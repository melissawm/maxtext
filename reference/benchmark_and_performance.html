
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Benchmark and Performance Tuning &#8212; MaxText  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=3ac9c114" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=c73c0f3e"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'reference/benchmark_and_performance';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="MaxText architecture overview" href="architecture_overview.html" />
    <link rel="prev" title="Comparison to Alternatives" href="alternatives.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/maxtext.png" class="logo__image only-light" alt="MaxText  documentation - Home"/>
    <script>document.write(`<img src="../_static/maxtext.png" class="logo__image only-dark" alt="MaxText  documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    MaxText
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorials.html">Tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/first_run.html">Getting Started: First Run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/full_finetuning.html">Full Finetuning LLama3-8B  Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/run_llama2.html">About Llama2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/grpo.html">Try GRPO!</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/sft.html">Try SFT!</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../guides.html">How-to Guides</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../guides/checkpoints.html">Checkpoints</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/custom_model.html">How to customize your model configs on TPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/run_maxtext_localhost.html">Run MaxText on Localhost or Single Host VM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/run_maxtext_via_xpk.html">Running MaxText at Scale with XPK</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/run_maxtext_via_pathways.html">Guide: Running MaxText via Pathways</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../guides/data_input_pipeline.html">Manage the data input pipeline</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../guides/data_input_grain.html">Grain pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../guides/data_input_hf.html">Hugging Face pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../guides/data_input_tfds.html">TFDS pipeline</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/single_host_gpu.html">Maxtext on Single host GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/knowledge_distillation.html">Knowledge Distillation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/gcp_workload_observability.html">Enable GCP Workload Observabiltiy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/monitor_goodput.html">ML Goodput Measurement</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/use_vertex_ai_tensorboard.html">Use Vertex AI Tensorboard</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/features_and_diagnostics.html">Features and Diagnostics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/pallas_kernels_performance.html">Performance Optimizations with Pallas Kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/performance_metrics.html">Performance Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/understand_logs_and_metrics.html">Understand Logs and Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/checkpointing_solutions/gcs_checkpointing.html">GCS bucket-based checkpointing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/checkpointing_solutions/emergency_checkpointing.html">Emergency Checkpointing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/checkpointing_solutions/multi_tier_checkpointing.html">Multi-Tier Checkpointing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/jax_ai_libraries_chosen.html">The JAX Ecosystem in MaxText: An Opinionated Guide</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../explanations.html">Explanations</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../explanations/steps_model.html">Steps to build a Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../explanations/quantization.html">Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../explanations/sharding.html">Sharding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../explanations/data_pipeline_perf.html">Data input pipeline performance</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../reference.html">Reference documentation</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="terminology.html">Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="supported_models_and_architectures.html">Supported Models &amp; Architectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="alternatives.html">Comparison to Alternatives</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Benchmark and Performance Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture_overview.html">MaxText architecture overview</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../development.html">How to Contribute</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/AI-Hypercomputer/maxtext" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/reference/benchmark_and_performance.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Benchmark and Performance Tuning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-setup-benchmark">How to Setup Benchmark</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#benchmark-with-synthetic-data-and-repeated-batches">Benchmark with synthetic data and repeated batches</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#start-with-arithmetic-intensity-analysis">Start with arithmetic intensity analysis</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metrics-for-benchmark-analysis">Metrics for Benchmark Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tuning-benchmark-performance">Tuning benchmark performance</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tuning-remat-policy">Tuning Remat Policy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#low-precision-training"><strong>Low Precision Training</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#choose-sharding-strategy">Choose Sharding Strategy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-tuning-on-custom-pallas-call">Performance Tuning on Custom Pallas call</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#communication-overlaps-and-tuning">Communication Overlaps and Tuning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scoped-vmem-tuning">Scoped Vmem Tuning</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="benchmark-and-performance-tuning">
<h1>Benchmark and Performance Tuning<a class="headerlink" href="#benchmark-and-performance-tuning" title="Link to this heading">#</a></h1>
<p>This tutorial guides you through setting up benchmarks and performing performance tuning in MaxText, <strong>focusing on key aspects</strong> like how to set up benchmarks, choose the right config and tuning the benchmark performance.</p>
<section id="how-to-setup-benchmark">
<h2>How to Setup Benchmark<a class="headerlink" href="#how-to-setup-benchmark" title="Link to this heading">#</a></h2>
<p>Setting up effective benchmarks is crucial for accurate performance tuning. Here’s how to approach it:</p>
<section id="benchmark-with-synthetic-data-and-repeated-batches">
<h3>Benchmark with synthetic data and repeated batches<a class="headerlink" href="#benchmark-with-synthetic-data-and-repeated-batches" title="Link to this heading">#</a></h3>
<p>To efficiently benchmark MaxText without large, real datasets, use synthetic data to eliminate input and pipeline bottlenecks.</p>
<p>set <code class="docutils literal notranslate"><span class="pre">dataset_type</span></code> to “synthetic” and <code class="docutils literal notranslate"><span class="pre">reuse_example_batch</span></code> to 1.</p>
</section>
<section id="start-with-arithmetic-intensity-analysis">
<h3>Start with arithmetic intensity analysis<a class="headerlink" href="#start-with-arithmetic-intensity-analysis" title="Link to this heading">#</a></h3>
<p>Begin your benchmarking efforts by performing an arithmetic intensity analysis. This fundamental step helps you determine the ideal batch size and sharding strategy for your specific hardware and workload. Based on your analysis and hardware configuration, select the sharding approach that yields the best results.</p>
<p>Arithmetic intensity is calculated as the ratio of floating-point operations (FLOPs) to memory(bytes) or communication(bytes).</p>
<ul class="simple">
<li><p><strong>Arithmetic Intensity = FLOPs / Bytes</strong></p></li>
</ul>
<p>This metric helps determine whether a computation is MXU-bound (high arithmetic intensity) or memory-bound/communication-bound (low arithmetic intensity).</p>
<p><a class="reference internal" href="../explanations/sharding.html#sharding"><span class="std std-ref">This sharding document</span></a> illustrates various sharding strategies and their roofline analysis, through AI analysis.</p>
</section>
</section>
<section id="metrics-for-benchmark-analysis">
<h2>Metrics for Benchmark Analysis<a class="headerlink" href="#metrics-for-benchmark-analysis" title="Link to this heading">#</a></h2>
<p>For benchmarking purposes, we collect the step time for training. This step time is then used to calculate MFU and throughputs, which provide insights into the utilization achieved for each benchmark workload.</p>
<ul class="simple">
<li><p><strong>MFU = flops_train_step / step_time / peak HW FLOPS</strong></p></li>
<li><p><strong>Throughput = global tokens / step_time / number of devices</strong></p></li>
</ul>
<p>More detailed are explained in <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/main/docs/guides/performance_metrics.md">performance_metrics </a></p>
</section>
<section id="tuning-benchmark-performance">
<h2>Tuning benchmark performance<a class="headerlink" href="#tuning-benchmark-performance" title="Link to this heading">#</a></h2>
<section id="tuning-remat-policy">
<h3>Tuning Remat Policy<a class="headerlink" href="#tuning-remat-policy" title="Link to this heading">#</a></h3>
<p>Rematerialization (remat) is a technique used to reduce memory consumption during model training. It works by recomputing activations during the backward pass instead of storing them in memory during the forward pass. This can be particularly beneficial for large models where memory is a bottleneck.</p>
<p>When tuning remat policy, the goal is to find a balance between memory savings and computational overhead. Recomputing activations consumes FLOPs, so aggressive rematerialization can increase training time. However, if memory is the limiting factor, remat can enable larger batch sizes or model sizes, ultimately leading to faster training or the ability to train models that would otherwise be impossible.</p>
<p>If there is enough host HBM memory, activations can be offloaded to host memory to save the recompute.</p>
<p>MaxText offers both preset and granular re-materialization policies, allowing you to tailor them to your specific requirements.</p>
<p><strong>Provided Remat Policies</strong></p>
<p>Remat policies can be chosen from: <code class="docutils literal notranslate"><span class="pre">minimal_with_context</span></code>, <code class="docutils literal notranslate"><span class="pre">minimal</span></code>, <code class="docutils literal notranslate"><span class="pre">save_dot_with_context_except_mlp</span></code>, <code class="docutils literal notranslate"><span class="pre">save_dot_except_mlpwi</span></code>, <code class="docutils literal notranslate"><span class="pre">save_dot_except_mlp</span></code>, <code class="docutils literal notranslate"><span class="pre">save_qkv_proj</span></code>, <code class="docutils literal notranslate"><span class="pre">qkv_proj_offloaded</span></code>, <code class="docutils literal notranslate"><span class="pre">custom</span></code>, <code class="docutils literal notranslate"><span class="pre">minimal_offloaded</span></code>, <code class="docutils literal notranslate"><span class="pre">save_out_proj</span></code> and <code class="docutils literal notranslate"><span class="pre">full</span></code>.</p>
<p>These options offer a trade-off between speed (fastest to slowest) and HBM usage (highest to lowest)</p>
<p><code class="docutils literal notranslate"><span class="pre">minimal_with_context</span></code> consumes the most HBM memory, while <code class="docutils literal notranslate"><span class="pre">full</span></code> signifies minimal checkpointing, with everything being rematerialized. <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/main/src/MaxText/layers/decoders.py#L287">more explanation and latest support</a></p>
<p><strong>Custom Policy</strong></p>
<p>To use a custom policy, set <code class="docutils literal notranslate"><span class="pre">remat_policy</span></code> to <code class="docutils literal notranslate"><span class="pre">custom</span></code> and specify the layers in the decode module as <code class="docutils literal notranslate"><span class="pre">offload</span></code>, <code class="docutils literal notranslate"><span class="pre">device</span></code>, or <code class="docutils literal notranslate"><span class="pre">remat</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">offload</span></code>: The tensor is offloaded to the CPU host.</p>
<p><code class="docutils literal notranslate"><span class="pre">device</span></code>: The activation remains on the TPU device.</p>
<p><code class="docutils literal notranslate"><span class="pre">Remat</span></code>: Rematerialization is performed during the backward pass.</p>
</section>
<section id="low-precision-training">
<h3><strong>Low Precision Training</strong><a class="headerlink" href="#low-precision-training" title="Link to this heading">#</a></h3>
<p>MaxText supports quantization via QWIX. To enable this, set <code class="docutils literal notranslate"><span class="pre">use_qwix_quantization=true</span></code>.</p>
<p>Different quantization recipes are available, including<code class="docutils literal notranslate"> <span class="pre">&quot;int8&quot;,</span> <span class="pre">&quot;fp8&quot;,</span> <span class="pre">&quot;fp8_full&quot;,</span> <span class="pre">&quot;fp8_gpu&quot;,</span> <span class="pre">and</span> <span class="pre">&quot;fp8_nanoo&quot;</span></code>.</p>
<p>For v6e and earlier generation TPUs, use the “int8” recipe. For v7x and later generation TPUs, use “fp8_full”. GPUs should use “fp8_gpu” for NVIDIA and “nanoo_fp8” for AMD.</p>
<p><a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/main/docs/explanations/quantization.md?plain=1">quantization doc</a></p>
</section>
<section id="choose-sharding-strategy">
<h3>Choose Sharding Strategy<a class="headerlink" href="#choose-sharding-strategy" title="Link to this heading">#</a></h3>
<p>Sharding is crucial for optimizing model performance. MaxText offers various sharding strategies and hybrid options, including FSDP, TP, EP, CP, and PP, which can be configured through your MaxText settings.</p>
<p><a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/main/docs/explanations/sharding.md">Scaling &amp; Sharding Concepts in MaxText</a> This document illustrates in detail how sharding works in maxtext and chooses the write sharding config for your workload.</p>
</section>
<section id="performance-tuning-on-custom-pallas-call">
<h3>Performance Tuning on Custom Pallas call<a class="headerlink" href="#performance-tuning-on-custom-pallas-call" title="Link to this heading">#</a></h3>
<p><a class="reference external" href="https://github.com/rdyro/tune-jax">Tune-jax</a> offers a tuning tool for Pallas kernels on both GPU and TPU. Users can tune custom kernels for specific model configurations by providing input shapes and defining a tuning search space.</p>
<p>Usage</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">functools</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tune_jax</span><span class="w"> </span><span class="kn">import</span> <span class="n">tune</span>

<span class="nd">@functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">tune</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;block_q&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">],</span> <span class="s1">&#39;block_k&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">]})</span>
<span class="k">def</span><span class="w"> </span><span class="nf">my_pallas_function</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
</pre></div>
</div>
<p>This example code will benchmark <code class="docutils literal notranslate"><span class="pre">my_pallas_function</span></code> across all combinations of <code class="docutils literal notranslate"><span class="pre">block_q</span></code> and <code class="docutils literal notranslate"><span class="pre">block_k</span></code>, automatically handling any compilation failures.</p>
</section>
<section id="communication-overlaps-and-tuning">
<h3>Communication Overlaps and Tuning<a class="headerlink" href="#communication-overlaps-and-tuning" title="Link to this heading">#</a></h3>
<p>There are two methods for asynchronous collective offloading:</p>
<ol class="arabic">
<li><p>Offload Collectives to Sparse Core:</p>
<p>This method is recommended for v7x. To enable it, set the following flags from[<a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/main/benchmarks/xla_flags_library.py#L70">link</a>]:</p>
</li>
</ol>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ENABLE_SPARSECORE_OFFLOADING_FOR_RS_AG_AR</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ENABLE_SPARSECORE_OFFLOADING_FOR_REDUCE_SCATTER</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ENABLE_SPARSECORE_OFFLOADING_FOR_ALL_GATHER</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ENABLE_SPARSECORE_OFFLOADING_FOR_ALL_REDUCE</span></code></p></li>
</ul>
<ol class="arabic" start="2">
<li><p>Overlap Collective Using Continuation Fusion:**</p>
<p>This method is recommended for v5p and v6e. To enable it, set the following flags[<a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/main/benchmarks/xla_flags_library.py#L39">link</a>]:</p>
</li>
</ol>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">CF_FOR_ALL_GATHER</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CF_FOR_ALL_REDUCE</span></code></p></li>
</ul>
<p>Those XLA can be set via <code class="docutils literal notranslate"><span class="pre">LIBTPU_INIT_ARGS</span></code></p>
</section>
<section id="scoped-vmem-tuning">
<h3>Scoped Vmem Tuning<a class="headerlink" href="#scoped-vmem-tuning" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">scoped_vmem</span></code> can be tuned using <code class="docutils literal notranslate"><span class="pre">xla_tpu_scoped_vmem_limit_kib</span></code>. The hardware limitations for vmem are 64M for v5e, 128M for v6e, and 64M for v7x.</p>
<p>This can be set via <code class="docutils literal notranslate"><span class="pre">LIBTPU_INIT_ARGS</span></code>, range can be 0 through harward limit. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">LIBTPU_INIT_ARGS</span><span class="o">=</span><span class="s2">&quot;---xla_tpu_scoped_vmem_limit_kib=65536&quot;</span>
</pre></div>
</div>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="alternatives.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Comparison to Alternatives</p>
      </div>
    </a>
    <a class="right-next"
       href="architecture_overview.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">MaxText architecture overview</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-setup-benchmark">How to Setup Benchmark</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#benchmark-with-synthetic-data-and-repeated-batches">Benchmark with synthetic data and repeated batches</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#start-with-arithmetic-intensity-analysis">Start with arithmetic intensity analysis</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metrics-for-benchmark-analysis">Metrics for Benchmark Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tuning-benchmark-performance">Tuning benchmark performance</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tuning-remat-policy">Tuning Remat Policy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#low-precision-training"><strong>Low Precision Training</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#choose-sharding-strategy">Choose Sharding Strategy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-tuning-on-custom-pallas-call">Performance Tuning on Custom Pallas call</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#communication-overlaps-and-tuning">Communication Overlaps and Tuning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scoped-vmem-tuning">Scoped Vmem Tuning</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By MaxText developers
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025, MaxText developers.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>