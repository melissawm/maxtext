
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Understand Logs and Metrics &#8212; MaxText  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=95a5a69d" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=c73c0f3e"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'guides/understand_logs_and_metrics';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="GCS bucket-based checkpointing" href="checkpointing_solutions/gcs_checkpointing.html" />
    <link rel="prev" title="Performance Metrics" href="performance_metrics.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/maxtext.png" class="logo__image only-light" alt="MaxText  documentation - Home"/>
    <script>document.write(`<img src="../_static/maxtext.png" class="logo__image only-dark" alt="MaxText  documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    MaxText
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorials.html">Tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/first_run.html">Getting Started: First Run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/pretraining.html">Pretraining with real datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/full_finetuning.html">Full Finetuning LLama3-8B  Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/run_llama2.html">About Llama2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/grpo.html">Try GRPO!</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/sft.html">Try SFT!</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/sft_on_multi_host.html">Supervised Fine-Tuning (SFT) with Deepseek-V3 Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/grpo_with_pathways.html">Try GRPO with Pathways!</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../guides.html">How-to Guides</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="checkpoints.html">Checkpoints</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_model.html">How to customize your model configs on TPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="run_maxtext_localhost.html">Run MaxText on Localhost or Single Host VM</a></li>
<li class="toctree-l2"><a class="reference internal" href="run_maxtext_via_xpk.html">Running MaxText at Scale with XPK</a></li>
<li class="toctree-l2"><a class="reference internal" href="run_maxtext_via_pathways.html">Guide: Running MaxText via Pathways</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="data_input_pipeline.html">Manage the data input pipeline</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="data_input_grain.html">Grain pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="data_input_hf.html">Hugging Face pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="data_input_tfds.html">TFDS pipeline</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="single_host_gpu.html">Maxtext on Single host GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="knowledge_distillation.html">Knowledge Distillation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gcp_workload_observability.html">Enable GCP Workload Observabiltiy</a></li>
<li class="toctree-l2"><a class="reference internal" href="monitor_goodput.html">ML Goodput Measurement</a></li>
<li class="toctree-l2"><a class="reference internal" href="use_vertex_ai_tensorboard.html">Use Vertex AI Tensorboard</a></li>
<li class="toctree-l2"><a class="reference internal" href="features_and_diagnostics.html">Features and Diagnostics</a></li>
<li class="toctree-l2"><a class="reference internal" href="pallas_kernels_performance.html">Performance Optimizations with Pallas Kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_metrics.html">Performance Metrics</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Understand Logs and Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="checkpointing_solutions/gcs_checkpointing.html">GCS bucket-based checkpointing</a></li>
<li class="toctree-l2"><a class="reference internal" href="checkpointing_solutions/emergency_checkpointing.html">Emergency Checkpointing</a></li>
<li class="toctree-l2"><a class="reference internal" href="checkpointing_solutions/multi_tier_checkpointing.html">Multi-Tier Checkpointing</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax_ai_libraries_chosen.html">The JAX Ecosystem in MaxText: An Opinionated Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="xprof_user_guide.html">XProf for MaxText developers</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../explanations.html">Explanations</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../explanations/steps_model.html">Steps to build a Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../explanations/quantization.html">Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../explanations/sharding.html">Sharding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../explanations/data_pipeline_perf.html">Data input pipeline performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../explanations/tiling.html">Tiling</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../reference.html">Reference documentation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../reference/terminology.html">Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/supported_models_and_architectures.html">Supported Models &amp; Architectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/alternatives.html">Comparison to Alternatives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/benchmark_and_performance.html">Benchmark and Performance Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/architecture_overview.html">MaxText architecture overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/jax_xla_and_pallas.html">JAX, XLA, and Pallas for MaxText users</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../development.html">How to Contribute</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/AI-Hypercomputer/maxtext" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/guides/understand_logs_and_metrics.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Understand Logs and Metrics</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration-information">1 Configuration information</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-output-paths">Understanding output paths</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#environment-information">2 Environment information</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resource-accounting">3 Resource accounting</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-analysis">3.1 Memory analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-snapshot">3.2 Memory snapshot</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-tflop-per-device">3.3 Model TFLOP per device</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-metrics">4 Training metrics</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-metrics">4.1 Performance metrics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-metrics">4.2 Learning metrics</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <!--
 Copyright 2023–2025 Google LLC

 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at

    https://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->
<section class="tex2jax_ignore mathjax_ignore" id="understand-logs-and-metrics">
<h1>Understand Logs and Metrics<a class="headerlink" href="#understand-logs-and-metrics" title="Link to this heading">#</a></h1>
<p>When you run a training job, MaxText produces detailed output logs. This guide shows you how to interpret these logs to understand your configuration and monitor performance.</p>
<p>To start, run a simple pretraining job on a single-host TPU. For instance, we can run the following command on TPU v5p-8. The resulting log is used as an example throughout this guide.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>MaxText.train<span class="w"> </span>src/MaxText/configs/base.yml<span class="w"> </span><span class="se">\</span>
<span class="nv">base_output_directory</span><span class="o">=</span>gs://runner-maxtext-logs<span class="w"> </span><span class="nv">run_name</span><span class="o">=</span>demo<span class="w"> </span><span class="se">\</span>
<span class="nv">model_name</span><span class="o">=</span>deepseek2-16b<span class="w"> </span><span class="se">\</span>
<span class="nv">per_device_batch_size</span><span class="o">=</span><span class="m">24</span><span class="w"> </span><span class="nv">max_target_length</span><span class="o">=</span><span class="m">2048</span><span class="w"> </span><span class="nv">steps</span><span class="o">=</span><span class="m">10</span><span class="w"> </span><span class="nv">dataset_type</span><span class="o">=</span>synthetic<span class="w"> </span><span class="nv">enable_checkpointing</span><span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
<section id="configuration-information">
<h2>1 Configuration information<a class="headerlink" href="#configuration-information" title="Link to this heading">#</a></h2>
<p>The first section of the log details the configuration of your run. This is crucial for debugging, as it shows you exactly which parameters were used.</p>
<p>MaxText builds its configuration in layers.</p>
<ul>
<li><p>It starts with the <strong>default configuration</strong> from a YAML file. In our example, the file is <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/ffb0d49adcc457e8cbe2872864b4034b21d43326/MaxText/configs/base.yml">MaxText/configs/base.yml</a>.</p></li>
<li><p>Then, it overwrites any of these values with the arguments you provide in the <strong>command line</strong>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Updating</span> <span class="n">keys</span> <span class="kn">from</span><span class="w"> </span><span class="nn">env</span> <span class="ow">and</span> <span class="n">command</span> <span class="n">line</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;run_name&#39;</span><span class="p">,</span> <span class="s1">&#39;model_name&#39;</span><span class="p">,</span> <span class="s1">&#39;enable_checkpointing&#39;</span><span class="p">,</span> <span class="s1">&#39;base_output_directory&#39;</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="s1">&#39;dataset_type&#39;</span><span class="p">,</span> <span class="s1">&#39;steps&#39;</span><span class="p">,</span> <span class="s1">&#39;max_target_length&#39;</span><span class="p">]</span>
</pre></div>
</div>
</li>
<li><p>It updates keys based on the <strong>model-specific configuration</strong> file. When you specify a model, like <code class="docutils literal notranslate"><span class="pre">deepseek2-16b</span></code>, MaxText reads the corresponding parameters from the <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/ffb0d49adcc457e8cbe2872864b4034b21d43326/MaxText/configs/models/deepseek2-16b.yml">deepseek2-16b.yml</a> file.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Running</span> <span class="n">Model</span><span class="p">:</span> <span class="n">deepseek2</span><span class="o">-</span><span class="mi">16</span><span class="n">b</span>
<span class="n">Updating</span> <span class="n">following</span> <span class="n">parameters</span> <span class="ow">in</span> <span class="n">config</span>

<span class="n">base_emb_dim</span><span class="p">:</span> <span class="mi">2048</span>
<span class="n">base_num_query_heads</span><span class="p">:</span> <span class="mi">16</span>
<span class="o">...</span>
<span class="n">Updating</span> <span class="n">keys</span> <span class="kn">from</span><span class="w"> </span><span class="nn">model</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;base_emb_dim&#39;</span><span class="p">,</span> <span class="s1">&#39;base_num_query_heads&#39;</span><span class="p">,</span> <span class="s1">&#39;base_num_kv_heads&#39;</span><span class="p">,</span> <span class="s1">&#39;base_mlp_dim&#39;</span><span class="p">,</span> <span class="s1">&#39;base_moe_mlp_dim&#39;</span><span class="p">,</span> <span class="s1">&#39;base_num_decoder_layers&#39;</span><span class="p">,</span> <span class="s1">&#39;first_num_dense_layers&#39;</span><span class="p">,</span> <span class="s1">&#39;mlp_activations&#39;</span><span class="p">,</span> <span class="s1">&#39;vocab_size&#39;</span><span class="p">,</span> <span class="s1">&#39;enable_dropout&#39;</span><span class="p">,</span> <span class="s1">&#39;logits_via_embedding&#39;</span><span class="p">,</span> <span class="s1">&#39;normalization_layer_epsilon&#39;</span><span class="p">,</span> <span class="s1">&#39;num_experts&#39;</span><span class="p">,</span> <span class="s1">&#39;num_experts_per_tok&#39;</span><span class="p">,</span> <span class="s1">&#39;shared_experts&#39;</span><span class="p">,</span> <span class="s1">&#39;routed_scaling_factor&#39;</span><span class="p">,</span> <span class="s1">&#39;routed_score_func&#39;</span><span class="p">,</span> <span class="s1">&#39;routed_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;decoder_block&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_type&#39;</span><span class="p">,</span> <span class="s1">&#39;q_lora_rank&#39;</span><span class="p">,</span> <span class="s1">&#39;kv_lora_rank&#39;</span><span class="p">,</span> <span class="s1">&#39;qk_nope_head_dim&#39;</span><span class="p">,</span> <span class="s1">&#39;qk_rope_head_dim&#39;</span><span class="p">,</span> <span class="s1">&#39;v_head_dim&#39;</span><span class="p">,</span> <span class="s1">&#39;rope_type&#39;</span><span class="p">,</span> <span class="s1">&#39;rope_max_timescale&#39;</span><span class="p">,</span> <span class="s1">&#39;max_position_embeddings&#39;</span><span class="p">,</span> <span class="s1">&#39;original_max_position_embeddings&#39;</span><span class="p">,</span> <span class="s1">&#39;rope_factor&#39;</span><span class="p">,</span> <span class="s1">&#39;beta_fast&#39;</span><span class="p">,</span> <span class="s1">&#39;mscale&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Note that you cannot modify a key from both model config and command line.</p>
</li>
</ul>
<p>The final, consolidated configuration is printed last.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># From base.yml default</span>
<span class="n">Config</span> <span class="n">param</span> <span class="n">opt_type</span><span class="p">:</span> <span class="n">adamw</span> 
<span class="o">...</span>
<span class="c1"># From model config</span>
<span class="n">Config</span> <span class="n">param</span> <span class="n">base_emb_dim</span><span class="p">:</span> <span class="mi">2048</span> 
<span class="o">...</span>
<span class="c1"># From command line</span>
<span class="n">Config</span> <span class="n">param</span> <span class="n">dataset_type</span><span class="p">:</span> <span class="n">synthetic</span>
<span class="n">Config</span> <span class="n">param</span> <span class="n">steps</span><span class="p">:</span> <span class="mi">10</span>
<span class="n">Config</span> <span class="n">param</span> <span class="n">per_device_batch_size</span><span class="p">:</span> <span class="mf">24.0</span>
<span class="n">Config</span> <span class="n">param</span> <span class="n">max_target_length</span><span class="p">:</span> <span class="mi">2048</span>
<span class="o">...</span>
<span class="c1"># Other config behind the scene</span>
<span class="n">Config</span> <span class="n">param</span> <span class="n">data_sharding</span><span class="p">:</span> <span class="p">((</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;stage&#39;</span><span class="p">,</span> <span class="s1">&#39;fsdp&#39;</span><span class="p">,</span> <span class="s1">&#39;fsdp_transpose&#39;</span><span class="p">,</span> <span class="s1">&#39;sequence&#39;</span><span class="p">,</span> <span class="s1">&#39;context&#39;</span><span class="p">,</span> <span class="s1">&#39;context_autoregressive&#39;</span><span class="p">,</span> <span class="s1">&#39;tensor&#39;</span><span class="p">,</span> <span class="s1">&#39;tensor_transpose&#39;</span><span class="p">,</span> <span class="s1">&#39;tensor_sequence&#39;</span><span class="p">,</span> <span class="s1">&#39;expert&#39;</span><span class="p">,</span> <span class="s1">&#39;autoregressive&#39;</span><span class="p">),)</span>
<span class="o">...</span>
</pre></div>
</div>
<p>This also includes the <strong>output paths</strong> for your run artifacts.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Config</span> <span class="n">param</span> <span class="n">base_output_directory</span><span class="p">:</span> <span class="n">gs</span><span class="p">:</span><span class="o">//</span><span class="n">runner</span><span class="o">-</span><span class="n">maxtext</span><span class="o">-</span><span class="n">logs</span>
<span class="n">Config</span> <span class="n">param</span> <span class="n">run_name</span><span class="p">:</span> <span class="n">demo</span>
<span class="n">Config</span> <span class="n">param</span> <span class="n">metrics_dir</span><span class="p">:</span> <span class="n">gs</span><span class="p">:</span><span class="o">//</span><span class="n">runner</span><span class="o">-</span><span class="n">maxtext</span><span class="o">-</span><span class="n">logs</span><span class="o">/</span><span class="n">demo</span><span class="o">/</span><span class="n">metrics</span><span class="o">/</span>
<span class="n">Config</span> <span class="n">param</span> <span class="n">tensorboard_dir</span><span class="p">:</span> <span class="n">gs</span><span class="p">:</span><span class="o">//</span><span class="n">runner</span><span class="o">-</span><span class="n">maxtext</span><span class="o">-</span><span class="n">logs</span><span class="o">/</span><span class="n">demo</span><span class="o">/</span><span class="n">tensorboard</span><span class="o">/</span>
<span class="n">Config</span> <span class="n">param</span> <span class="n">checkpoint_dir</span><span class="p">:</span> <span class="n">gs</span><span class="p">:</span><span class="o">//</span><span class="n">runner</span><span class="o">-</span><span class="n">maxtext</span><span class="o">-</span><span class="n">logs</span><span class="o">/</span><span class="n">demo</span><span class="o">/</span><span class="n">checkpoints</span><span class="o">/</span>
</pre></div>
</div>
<section id="understanding-output-paths">
<h3>Understanding output paths<a class="headerlink" href="#understanding-output-paths" title="Link to this heading">#</a></h3>
<p>MaxText organizes all of your run’s artifacts into a main output directory. The primary location for your run is constructed by combining the <code class="docutils literal notranslate"><span class="pre">base_output_directory</span></code> and the <code class="docutils literal notranslate"><span class="pre">run_name</span></code> you specify in your command. Based on the logs above, the base path for this specific run is <code class="docutils literal notranslate"><span class="pre">gs://runner-maxtext-logs/demo</span></code>.</p>
<p>Within this base path, MaxText creates several subdirectories for different types of artifacts. Many of these are optional and only created if you enable them with a specific flag.</p>
<ul class="simple">
<li><p><strong>TensorBoard logs (<code class="docutils literal notranslate"><span class="pre">tensorboard/</span></code>)</strong></p>
<ul>
<li><p>Flag: <code class="docutils literal notranslate"><span class="pre">enable_tensorboard=True</span></code> (default)</p></li>
<li><p>Path: <code class="docutils literal notranslate"><span class="pre">gs://runner-maxtext-logs/demo/tensorboard/</span></code></p></li>
</ul>
</li>
<li><p><strong>Profiler traces (<code class="docutils literal notranslate"><span class="pre">tensorboard/plugins/profile/</span></code>)</strong></p>
<ul>
<li><p>Flag: <code class="docutils literal notranslate"><span class="pre">profiler=xplane</span></code></p></li>
<li><p>Path: The profiler output is saved within the TensorBoard directory.</p></li>
</ul>
</li>
<li><p><strong>Metrics in plain text (<code class="docutils literal notranslate"><span class="pre">metrics/</span></code>)</strong></p>
<ul>
<li><p>Flag: <code class="docutils literal notranslate"><span class="pre">gcs_metrics=True</span></code></p></li>
<li><p>Path: <code class="docutils literal notranslate"><span class="pre">gs://runner-maxtext-logs/demo/metrics/</span></code></p></li>
</ul>
</li>
<li><p><strong>Configuration file (<code class="docutils literal notranslate"><span class="pre">config.yml</span></code>)</strong></p>
<ul>
<li><p>Flag: <code class="docutils literal notranslate"><span class="pre">save_config_to_gcs=True</span></code></p></li>
<li><p>Path: <code class="docutils literal notranslate"><span class="pre">gs://runner-maxtext-logs/demo/config.yml</span></code></p></li>
</ul>
</li>
<li><p><strong>Checkpoints (<code class="docutils literal notranslate"><span class="pre">checkpoints/</span></code>)</strong></p>
<ul>
<li><p>Flag: <code class="docutils literal notranslate"><span class="pre">enable_checkpointing=True</span></code></p></li>
<li><p>Path: <code class="docutils literal notranslate"><span class="pre">gs://runner-maxtext-logs/demo/checkpoints/</span></code></p></li>
</ul>
</li>
</ul>
<p>To generate all optional artifacts in one run, you can set the corresponding flags in the command line, like in the example below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># This command enables tensorboard, profiler, text metrics, config saving, and checkpointing</span>
python3<span class="w"> </span>-m<span class="w"> </span>MaxText.train<span class="w"> </span>src/MaxText/configs/base.yml<span class="w"> </span><span class="se">\</span>
<span class="nv">base_output_directory</span><span class="o">=</span>gs://runner-maxtext-logs<span class="w"> </span><span class="nv">run_name</span><span class="o">=</span>demo2<span class="w"> </span><span class="se">\</span>
<span class="nv">model_name</span><span class="o">=</span>deepseek2-16b<span class="w"> </span><span class="se">\</span>
<span class="nv">per_device_batch_size</span><span class="o">=</span><span class="m">24</span><span class="w"> </span><span class="nv">max_target_length</span><span class="o">=</span><span class="m">2048</span><span class="w"> </span><span class="nv">steps</span><span class="o">=</span><span class="m">10</span><span class="w"> </span><span class="nv">dataset_type</span><span class="o">=</span>synthetic<span class="w"> </span><span class="se">\</span>
<span class="nv">enable_tensorboard</span><span class="o">=</span>True<span class="w"> </span><span class="se">\</span>
<span class="nv">profiler</span><span class="o">=</span>xplane<span class="w"> </span><span class="nv">skip_first_n_steps_for_profiler</span><span class="o">=</span><span class="m">5</span><span class="w"> </span><span class="nv">profiler_steps</span><span class="o">=</span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
<span class="nv">gcs_metrics</span><span class="o">=</span>True<span class="w"> </span><span class="se">\</span>
<span class="nv">save_config_to_gcs</span><span class="o">=</span>True<span class="w"> </span><span class="se">\</span>
<span class="nv">enable_checkpointing</span><span class="o">=</span>True<span class="w"> </span>
</pre></div>
</div>
</section>
</section>
<section id="environment-information">
<h2>2 Environment information<a class="headerlink" href="#environment-information" title="Link to this heading">#</a></h2>
<p>Next, the log displays the software and hardware environment for your run. This is useful for verifying your setup and understanding how parallelism is being applied.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">System</span> <span class="n">Information</span><span class="p">:</span> <span class="n">Jax</span> <span class="n">Version</span><span class="p">:</span> <span class="mf">0.7.2</span><span class="o">.</span><span class="n">dev20250826</span>
<span class="n">System</span> <span class="n">Information</span><span class="p">:</span> <span class="n">Jaxlib</span> <span class="n">Version</span><span class="p">:</span> <span class="mf">0.7.2</span><span class="o">.</span><span class="n">dev20250826</span>
<span class="n">System</span> <span class="n">Information</span><span class="p">:</span> <span class="n">Jax</span> <span class="n">Backend</span><span class="p">:</span> <span class="n">PJRT</span> <span class="n">C</span> <span class="n">API</span>
<span class="n">TFRT</span> <span class="n">TPU</span> <span class="n">v5</span>
<span class="n">Num_devices</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">shape</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p><strong>Software</strong>: You can confirm the versions of <code class="docutils literal notranslate"><span class="pre">Jax</span></code> and <code class="docutils literal notranslate"><span class="pre">Jaxlib</span></code>, which are core frameworks for the MaxText library.</p></li>
<li><p><strong>Hardware</strong>: You are running on the <code class="docutils literal notranslate"><span class="pre">TPU</span> <span class="pre">v5</span></code> accelerator with <code class="docutils literal notranslate"><span class="pre">4</span></code> total devices.</p></li>
<li><p><strong>Parallelism strategy</strong>: The <code class="docutils literal notranslate"><span class="pre">shape</span></code> tuple <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">1,</span> <span class="pre">4,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">1)</span></code> shows how your devices are arranged for parallelism. Recall from Section 1, <code class="docutils literal notranslate"><span class="pre">Config</span> <span class="pre">param</span> <span class="pre">data_sharding:</span> <span class="pre">(('data',</span> <span class="pre">'stage',</span> <span class="pre">'fsdp',</span> <span class="pre">'fsdp_transpose',</span> <span class="pre">'sequence',</span> <span class="pre">'context',</span> <span class="pre">'context_autoregressive',</span> <span class="pre">'tensor',</span> <span class="pre">'tensor_transpose',</span> <span class="pre">'tensor_sequence',</span> <span class="pre">'expert',</span> <span class="pre">'autoregressive'),)</span></code>. This confirms that all 4 devices are being used for Fully Sharded Data Parallelism (FSDP), which is the default behavior.</p></li>
</ul>
</section>
<section id="resource-accounting">
<h2>3 Resource accounting<a class="headerlink" href="#resource-accounting" title="Link to this heading">#</a></h2>
<p>Before executing training, the program analyzes the resource requirements for your training job, specifically memory and compute (FLOPs).</p>
<section id="memory-analysis">
<h3>3.1 Memory analysis<a class="headerlink" href="#memory-analysis" title="Link to this heading">#</a></h3>
<p>We first perform a “dry run” compilation of a training step to <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/f82ce194c490d668b14574a072a0a630c27bbd6e/MaxText/train.py#L630-L632">analyze its memory requirement</a>. This static analysis is performed by the XLA compiler. The log outputs <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/f82ce194c490d668b14574a072a0a630c27bbd6e/MaxText/max_utils.py#L735-L753">memory sizes</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Total</span> <span class="n">memory</span> <span class="n">size</span><span class="p">:</span> <span class="mf">100.4</span> <span class="n">GB</span><span class="p">,</span> <span class="n">Output</span> <span class="n">size</span><span class="p">:</span> <span class="mf">44.5</span> <span class="n">GB</span><span class="p">,</span> <span class="n">Temp</span> <span class="n">size</span><span class="p">:</span> <span class="mf">55.9</span> <span class="n">GB</span><span class="p">,</span> <span class="n">Argument</span> <span class="n">size</span><span class="p">:</span> <span class="mf">44.5</span> <span class="n">GB</span><span class="p">,</span> <span class="n">Host</span> <span class="n">temp</span> <span class="n">size</span><span class="p">:</span> <span class="mf">0.0</span> <span class="n">GB</span><span class="o">.</span>
</pre></div>
</div>
<p>The most important number is <code class="docutils literal notranslate"><span class="pre">Total</span> <span class="pre">memory</span> <span class="pre">size:</span> <span class="pre">100.4</span> <span class="pre">GB</span></code>. This is the total High Bandwidth Memory (HBM) the TPU device needs to execute the program. Here is a breakdown:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Argument</span> <span class="pre">size:</span> <span class="pre">44.5</span> <span class="pre">GB</span></code>: This is the memory needed to hold the inputs for your function. This typically includes the batch of data, parameter (master copy), and optimizer state (e.g., moment).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Output</span> <span class="pre">size:</span> <span class="pre">44.5</span> <span class="pre">GB</span></code>: This is the space required to store the results of the computation, such as the updated model weights and updated optimizer states.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Temp</span> <span class="pre">size:</span> <span class="pre">55.9</span> <span class="pre">GB</span></code>: This is the “scratch space” memory. It’s used for all the intermediate values created during the forward and backward passes that are discarded once the step is complete. This includes activation (forward pass), gradient (backward pass), and parameter (working copy, if mixed precision).</p></li>
<li><p>Memory aliasing: You might notice that the sum of the parts is greater than <code class="docutils literal notranslate"><span class="pre">100.4</span> <span class="pre">GB</span> <span class="pre">(total)</span></code>: <code class="docutils literal notranslate"><span class="pre">44.5</span> <span class="pre">GB</span> <span class="pre">(Argument)</span> <span class="pre">+</span> <span class="pre">44.5</span> <span class="pre">GB</span> <span class="pre">(Output)</span> <span class="pre">+</span> <span class="pre">55.9</span> <span class="pre">GB</span> <span class="pre">(Temp)</span> <span class="pre">=</span> <span class="pre">144.9</span> <span class="pre">GB</span></code>. The difference is due to a compiler optimization called memory aliasing. The compiler reuses memory blocks. The true calculation is <code class="docutils literal notranslate"><span class="pre">Total</span> <span class="pre">=</span> <span class="pre">Argument</span> <span class="pre">+</span> <span class="pre">Output</span> <span class="pre">+</span> <span class="pre">Temp</span> <span class="pre">-</span> <span class="pre">Aliased</span></code>. In our case, the compiler identified <code class="docutils literal notranslate"><span class="pre">44.5</span> <span class="pre">GB</span> <span class="pre">(144.9</span> <span class="pre">GB</span> <span class="pre">-</span> <span class="pre">100.4</span> <span class="pre">GB)</span></code> of memory that could be safely reused. Most likely, it reuses memory for <code class="docutils literal notranslate"><span class="pre">Argument</span></code> and <code class="docutils literal notranslate"><span class="pre">Output</span></code>.</p></li>
</ul>
<p>In addition, it shows temporary memory used on the host CPU. In this case, <code class="docutils literal notranslate"><span class="pre">Host</span> <span class="pre">temp</span> <span class="pre">size:</span> <span class="pre">0.0</span> <span class="pre">GB</span></code>, indicating that all the significant memory allocation happens on the accelerator device.</p>
</section>
<section id="memory-snapshot">
<h3>3.2 Memory snapshot<a class="headerlink" href="#memory-snapshot" title="Link to this heading">#</a></h3>
<p>The previous section is a forecast of memory usage for entire training step, based on static analysis of the compiled code from the XLA compiler. To see the actual memory usage, we now turn to a real-time snapshot from the JAX runtime, captured right after the training state is initialized.</p>
<p>To set the stage for training, we first initialize the training state, which include parameter and optimizer states. At the <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/f82ce194c490d668b14574a072a0a630c27bbd6e/MaxText/train.py#L695">beginning</a>, the log shows a real-time snapshot of the <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/f82ce194c490d668b14574a072a0a630c27bbd6e/MaxText/max_utils.py#L708-L717">memory statistics</a> on your TPU devices.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">number</span> <span class="n">parameters</span><span class="p">:</span> <span class="mf">15.933</span> <span class="n">billion</span>

<span class="n">Memstats</span><span class="p">:</span> <span class="n">After</span> <span class="n">params</span> <span class="n">initialized</span><span class="p">:</span>
	<span class="n">Using</span> <span class="p">(</span><span class="n">GB</span><span class="p">)</span> <span class="mf">44.63</span> <span class="o">/</span> <span class="mf">95.74</span> <span class="p">(</span><span class="mf">46.615835</span><span class="o">%</span><span class="p">)</span> <span class="n">on</span> <span class="n">TPU_0</span><span class="p">(</span><span class="n">process</span><span class="o">=</span><span class="mi">0</span><span class="p">,(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
	<span class="n">Using</span> <span class="p">(</span><span class="n">GB</span><span class="p">)</span> <span class="mf">44.63</span> <span class="o">/</span> <span class="mf">95.74</span> <span class="p">(</span><span class="mf">46.615835</span><span class="o">%</span><span class="p">)</span> <span class="n">on</span> <span class="n">TPU_1</span><span class="p">(</span><span class="n">process</span><span class="o">=</span><span class="mi">0</span><span class="p">,(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
	<span class="n">Using</span> <span class="p">(</span><span class="n">GB</span><span class="p">)</span> <span class="mf">44.63</span> <span class="o">/</span> <span class="mf">95.74</span> <span class="p">(</span><span class="mf">46.615835</span><span class="o">%</span><span class="p">)</span> <span class="n">on</span> <span class="n">TPU_2</span><span class="p">(</span><span class="n">process</span><span class="o">=</span><span class="mi">0</span><span class="p">,(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
	<span class="n">Using</span> <span class="p">(</span><span class="n">GB</span><span class="p">)</span> <span class="mf">44.63</span> <span class="o">/</span> <span class="mf">95.74</span> <span class="p">(</span><span class="mf">46.615835</span><span class="o">%</span><span class="p">)</span> <span class="n">on</span> <span class="n">TPU_3</span><span class="p">(</span><span class="n">process</span><span class="o">=</span><span class="mi">0</span><span class="p">,(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
<p>This log shows that each of the four TPUs has <code class="docutils literal notranslate"><span class="pre">95.74</span> <span class="pre">GB</span></code> of available High Bandwidth Memory (HBM). The initial training state is evenly distributed across devices, with each using the same amount of <code class="docutils literal notranslate"><span class="pre">44.63</span> <span class="pre">GB</span></code>.</p>
</section>
<section id="model-tflop-per-device">
<h3>3.3 Model TFLOP per device<a class="headerlink" href="#model-tflop-per-device" title="Link to this heading">#</a></h3>
<p>The <strong>model FLOPs</strong> are the floating point operations to perform model computation. For training, the computation includes a single forward and backward pass.</p>
<ul class="simple">
<li><p>In MaxText, we estimate model FLOPs by summing operations in matrix multiplications (matmuls); see <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/e969faabbb571285a51545530f34d8f0a9f237e9/MaxText/maxtext_utils.py#L297">calculate_tflops_training_per_device</a>.</p></li>
<li><p>The number of model FLOPs is dependent on model architecture, input size (batch size, sequence length), and gradient accumulation steps. It does not include optimization operations.</p></li>
<li><p>We break down the FLOPs into two parts:</p>
<ul>
<li><p>“Learnable weight FLOPs” are matmuls between activations and learnable weights. Specifically, this occurs in embedding, feed forward networks, attention-related projections, and unembedding.</p></li>
<li><p>“Attention FLOPs” are matmuls in attention score computation like <span class="math notranslate nohighlight">\(\mathrm{softmax}{\left(\frac{QK^\top}{\sqrt{d}}\right)} V\)</span>.</p></li>
</ul>
</li>
</ul>
<p>One <strong>TFLOP</strong> (TeraFLOP) is equal to <span class="math notranslate nohighlight">\(10^{12}\)</span> FLOPs. The log shows the theoretical estimate of <strong>model TFLOP per device</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Per</span> <span class="n">train</span> <span class="n">step</span><span class="p">:</span>
 <span class="n">Total</span> <span class="n">TFLOPs</span><span class="p">:</span> <span class="mf">764.67</span> 
 <span class="n">split</span> <span class="k">as</span> <span class="mf">94.54</span><span class="o">%</span> <span class="n">learnable</span> <span class="n">weight</span> <span class="n">flops</span> <span class="ow">and</span> <span class="mf">5.46</span><span class="o">%</span> <span class="n">attention</span> <span class="n">flops</span>
</pre></div>
</div>
<p>In this example, given <code class="docutils literal notranslate"><span class="pre">model=deepseek2-16b</span></code>, <code class="docutils literal notranslate"><span class="pre">per_device_batch_size=24</span></code>, <code class="docutils literal notranslate"><span class="pre">max_target_length=2048</span></code>, and no gradient accumulation, we have <span class="math notranslate nohighlight">\(\text{model tflop per device} \approx 764.67\)</span>.</p>
<ul class="simple">
<li><p>94.54% of the TFLOPs are attributed to learnable weight and 5.46% are attributed to attention.</p></li>
<li><p>As you will see next, this number is important for calculating performance metrics, such as TFLOP/s/device and Model FLOPs Utilization (MFU).</p></li>
</ul>
<p>You can find more information about model FLOPs and MFU in the <a class="reference internal" href="performance_metrics.html"><span class="std std-doc">Performance Metrics</span></a> topic.</p>
</section>
</section>
<section id="training-metrics">
<h2>4 Training metrics<a class="headerlink" href="#training-metrics" title="Link to this heading">#</a></h2>
<p>Finally, we are getting to the training steps! In this section, we introduce performance metrics including TFLOP/s/device, MFU, and Tokens/s/device (throughput). We briefly cover learning metrics including loss and total weights.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">completed</span> <span class="n">step</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="n">seconds</span><span class="p">:</span> <span class="mf">44.923</span><span class="p">,</span> <span class="n">TFLOP</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">17.022</span><span class="p">,</span> <span class="n">Tokens</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">1094.129</span><span class="p">,</span> <span class="n">total_weights</span><span class="p">:</span> <span class="mi">196608</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">12.038</span>
<span class="n">completed</span> <span class="n">step</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="n">seconds</span><span class="p">:</span> <span class="mf">0.319</span><span class="p">,</span> <span class="n">TFLOP</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">2400.734</span><span class="p">,</span> <span class="n">Tokens</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">154316.608</span><span class="p">,</span> <span class="n">total_weights</span><span class="p">:</span> <span class="mi">196608</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">12.038</span>
<span class="n">completed</span> <span class="n">step</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="n">seconds</span><span class="p">:</span> <span class="mf">5.658</span><span class="p">,</span> <span class="n">TFLOP</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">135.158</span><span class="p">,</span> <span class="n">Tokens</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">8687.815</span><span class="p">,</span> <span class="n">total_weights</span><span class="p">:</span> <span class="mi">196608</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">11.689</span>
<span class="n">completed</span> <span class="n">step</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="n">seconds</span><span class="p">:</span> <span class="mf">5.402</span><span class="p">,</span> <span class="n">TFLOP</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">141.542</span><span class="p">,</span> <span class="n">Tokens</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">9098.189</span><span class="p">,</span> <span class="n">total_weights</span><span class="p">:</span> <span class="mi">196608</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">11.379</span>
<span class="n">completed</span> <span class="n">step</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="n">seconds</span><span class="p">:</span> <span class="mf">5.669</span><span class="p">,</span> <span class="n">TFLOP</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">134.884</span><span class="p">,</span> <span class="n">Tokens</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">8670.207</span><span class="p">,</span> <span class="n">total_weights</span><span class="p">:</span> <span class="mi">196608</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">11.110</span>
<span class="n">completed</span> <span class="n">step</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="n">seconds</span><span class="p">:</span> <span class="mf">5.668</span><span class="p">,</span> <span class="n">TFLOP</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">134.909</span><span class="p">,</span> <span class="n">Tokens</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">8671.794</span><span class="p">,</span> <span class="n">total_weights</span><span class="p">:</span> <span class="mi">196608</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">10.879</span>
<span class="n">completed</span> <span class="n">step</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="n">seconds</span><span class="p">:</span> <span class="mf">5.668</span><span class="p">,</span> <span class="n">TFLOP</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">134.914</span><span class="p">,</span> <span class="n">Tokens</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">8672.153</span><span class="p">,</span> <span class="n">total_weights</span><span class="p">:</span> <span class="mi">196608</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">10.688</span>
<span class="n">completed</span> <span class="n">step</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="n">seconds</span><span class="p">:</span> <span class="mf">5.669</span><span class="p">,</span> <span class="n">TFLOP</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">134.882</span><span class="p">,</span> <span class="n">Tokens</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">8670.101</span><span class="p">,</span> <span class="n">total_weights</span><span class="p">:</span> <span class="mi">196608</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">10.542</span>
<span class="n">completed</span> <span class="n">step</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="n">seconds</span><span class="p">:</span> <span class="mf">5.668</span><span class="p">,</span> <span class="n">TFLOP</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">134.911</span><span class="p">,</span> <span class="n">Tokens</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">8671.946</span><span class="p">,</span> <span class="n">total_weights</span><span class="p">:</span> <span class="mi">196608</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">10.440</span>
<span class="n">completed</span> <span class="n">step</span><span class="p">:</span> <span class="mi">9</span><span class="p">,</span> <span class="n">seconds</span><span class="p">:</span> <span class="mf">5.667</span><span class="p">,</span> <span class="n">TFLOP</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">134.924</span><span class="p">,</span> <span class="n">Tokens</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">8672.758</span><span class="p">,</span> <span class="n">total_weights</span><span class="p">:</span> <span class="mi">196608</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">10.374</span>
</pre></div>
</div>
<p>Before we dive deep here, recall a few numbers from previous sections:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\text{max target length} = 2048\)</span>, <span class="math notranslate nohighlight">\(\text{per device batch size} = 24\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\text{model tflop per device} \approx 764.67\)</span> (rounded), <span class="math notranslate nohighlight">\(\text{number of devices} = 4\)</span></p></li>
</ul>
<section id="performance-metrics">
<h3>4.1 Performance metrics<a class="headerlink" href="#performance-metrics" title="Link to this heading">#</a></h3>
<p>The performance metrics fluctuate at the beginning, and become stable towards the end. Therefore, we usually read them from the last step. Let’s take a closer look at Step 9.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">completed</span> <span class="n">step</span><span class="p">:</span> <span class="mi">9</span><span class="p">,</span> <span class="n">seconds</span><span class="p">:</span> <span class="mf">5.667</span><span class="p">,</span> <span class="n">TFLOP</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">134.924</span><span class="p">,</span> <span class="n">Tokens</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">8672.758</span><span class="p">,</span> <span class="n">total_weights</span><span class="p">:</span> <span class="mi">196608</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">10.374</span>
</pre></div>
</div>
<p>As shown in <code class="docutils literal notranslate"><span class="pre">seconds:</span> <span class="pre">5.667</span></code>, <span class="math notranslate nohighlight">\(\text{measured step time in seconds} \approx 5.667\)</span> (rounded).</p>
<p><strong>TFLOP per second per device</strong></p>
<ul class="simple">
<li><p>It is <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/e969faabbb571285a51545530f34d8f0a9f237e9/MaxText/metric_logger.py#L193-L194">computed</a> as</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text{tflop/s/device} = \frac{\text{model tflop per device}}{\text{measured step time in seconds}}\]</div>
<ul class="simple">
<li><p>Here we have <code class="docutils literal notranslate"><span class="pre">TFLOP/s/device:</span> <span class="pre">134.924</span></code>. Let’s try to verify manually: <span class="math notranslate nohighlight">\(764.67 / 5.667 = 134.934\)</span>. Not exactly the same but close, since the both tflop and time are rounded in the log.</p></li>
<li><p>Further, we can calculate <strong>Model FLOPs Utilization (MFU)</strong> from this:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text{MFU} = \frac{\text{tflop/s/device}}{\text{peak hardware tflop/s}}\]</div>
<p>For TPU v5p, <span class="math notranslate nohighlight">\(\text{peak hardware tflop/s}=459\)</span>. Thus, <span class="math notranslate nohighlight">\(134.924 / 459 = 29.40\)</span>%. Note this is an example for explanation with small batch size and sequence length, so the MFU is not optimal.</p>
<p><strong>Tokens per second per device (throughput)</strong></p>
<ul class="simple">
<li><p>It is <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/e969faabbb571285a51545530f34d8f0a9f237e9/MaxText/metric_logger.py#L197-L199">computed</a> as</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text{token/s/device} = \frac{\text{number of tokens per device}}{\text{measured step time in seconds}}\]</div>
<ul class="simple">
<li><p>The numerator is from <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/e969faabbb571285a51545530f34d8f0a9f237e9/MaxText/maxtext_utils.py#L151">calculate_tokens_training_per_device</a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text{number of tokens per device} = \text{per device batch size} \times \text{max target length}\]</div>
<ul class="simple">
<li><p>Here we have <code class="docutils literal notranslate"><span class="pre">Tokens/s/device:</span> <span class="pre">8672.758</span></code>. Let’s try to verify manually: <span class="math notranslate nohighlight">\(24 \times 2048 / 5.667 = 8673.372\)</span>. Not exactly the same but close, since the time is rounded in the log.</p></li>
</ul>
</section>
<section id="learning-metrics">
<h3>4.2 Learning metrics<a class="headerlink" href="#learning-metrics" title="Link to this heading">#</a></h3>
<p><strong>Loss</strong>. The loss is the key indicator of learning progress, which should decrease over training steps. In this example, the loss is <code class="docutils literal notranslate"><span class="pre">12.038</span></code> at Step 0 and decreases to <code class="docutils literal notranslate"><span class="pre">10.374</span></code> at Step 9. Ideally, we want the loss to converge to a small value with sufficiently large training steps.</p>
<p><strong>Total weights</strong>. When discussing the throughput, we have <span class="math notranslate nohighlight">\(\text{number of tokens} = \text{per device batch size} \times \text{max target length} \times \text{number of device}\)</span>. In this example, <span class="math notranslate nohighlight">\(\text{number of tokens} = 24 \times 2048 \times 4 = 196608\)</span>. There are two types of tokens: real tokens and pad tokens. The pad tokens are placeholders introduced by data preprocessing: We truncate or pad each sentence to max target length. Only real tokens contribute to the learning signal (i.e., loss). Therefore, we monitor <span class="math notranslate nohighlight">\(\text{number of real tokens}\)</span>, which is shown as <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/f82ce194c490d668b14574a072a0a630c27bbd6e/MaxText/train.py#L307">total weights</a>.</p>
<ul>
<li><p>Here we see <code class="docutils literal notranslate"><span class="pre">total_weights:</span> <span class="pre">196608</span></code> for all steps. This is because we are using <code class="docutils literal notranslate"><span class="pre">dataset_type=synthetic</span></code>, where all sentences are generated with a length of <code class="docutils literal notranslate"><span class="pre">max_target_length=2048</span></code>. As a result, there are no pad tokens and total weights = number of tokens.</p></li>
<li><p>However, in real datasets, sentences can have variable lengths and total weights &lt; number of tokens. For example, we can set <code class="docutils literal notranslate"><span class="pre">dataset_type=tfds</span> <span class="pre">dataset_path=gs://maxtext-dataset</span> <span class="pre">dataset_name='c4/en:3.0.1'</span></code>, and will see total weights smaller than <code class="docutils literal notranslate"><span class="pre">196608</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">completed</span> <span class="n">step</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="n">seconds</span><span class="p">:</span> <span class="mf">5.670</span><span class="p">,</span> <span class="n">TFLOP</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">134.856</span><span class="p">,</span> <span class="n">Tokens</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">8668.393</span><span class="p">,</span> <span class="n">total_weights</span><span class="p">:</span> <span class="mi">163259</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">9.596</span>
<span class="n">completed</span> <span class="n">step</span><span class="p">:</span> <span class="mi">9</span><span class="p">,</span> <span class="n">seconds</span><span class="p">:</span> <span class="mf">5.669</span><span class="p">,</span> <span class="n">TFLOP</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">134.884</span><span class="p">,</span> <span class="n">Tokens</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">device</span><span class="p">:</span> <span class="mf">8670.184</span><span class="p">,</span> <span class="n">total_weights</span><span class="p">:</span> <span class="mi">155934</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">9.580</span>
</pre></div>
</div>
</li>
<li><p>For better convergence, we want to have large total weights. Towards this end, MaxText supports <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/f82ce194c490d668b14574a072a0a630c27bbd6e/MaxText/sequence_packing.py#L39">packing</a> multiple short sequences into one. This is enabled by default with <code class="docutils literal notranslate"><span class="pre">packing=True</span></code> in <a class="reference external" href="https://github.com/AI-Hypercomputer/maxtext/blob/eff346c028092c4f4fd421e5c5343308def5de5a/MaxText/configs/base.yml#L454">base.yml</a>.</p></li>
</ul>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="performance_metrics.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Performance Metrics</p>
      </div>
    </a>
    <a class="right-next"
       href="checkpointing_solutions/gcs_checkpointing.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">GCS bucket-based checkpointing</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration-information">1 Configuration information</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-output-paths">Understanding output paths</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#environment-information">2 Environment information</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resource-accounting">3 Resource accounting</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-analysis">3.1 Memory analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-snapshot">3.2 Memory snapshot</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-tflop-per-device">3.3 Model TFLOP per device</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-metrics">4 Training metrics</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-metrics">4.1 Performance metrics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-metrics">4.2 Learning metrics</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By MaxText developers
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025, Google LLC.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>