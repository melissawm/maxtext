
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Features and Diagnostics &#8212; MaxText  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=3ac9c114" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=c73c0f3e"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'guides/features_and_diagnostics';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Performance Optimizations with Pallas Kernels" href="pallas_kernels_performance.html" />
    <link rel="prev" title="Use Vertex AI Tensorboard" href="use_vertex_ai_tensorboard.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/maxtext.png" class="logo__image only-light" alt="MaxText  documentation - Home"/>
    <script>document.write(`<img src="../_static/maxtext.png" class="logo__image only-dark" alt="MaxText  documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    MaxText
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorials.html">Tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/first_run.html">Getting Started: First Run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/full_finetuning.html">Full Finetuning LLama3-8B  Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/run_llama2.html">About Llama2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/grpo.html">Try GRPO!</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/sft.html">Try SFT!</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../guides.html">How-to Guides</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="checkpoints.html">Checkpoints</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_model.html">How to customize your model configs on TPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="run_maxtext_localhost.html">Run MaxText on Localhost or Single Host VM</a></li>
<li class="toctree-l2"><a class="reference internal" href="run_maxtext_via_xpk.html">Running MaxText at Scale with XPK</a></li>
<li class="toctree-l2"><a class="reference internal" href="run_maxtext_via_pathways.html">Guide: Running MaxText via Pathways</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="data_input_pipeline.html">Manage the data input pipeline</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="data_input_grain.html">Grain pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="data_input_hf.html">Hugging Face pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="data_input_tfds.html">TFDS pipeline</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="single_host_gpu.html">Maxtext on Single host GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="knowledge_distillation.html">Knowledge Distillation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gcp_workload_observability.html">Enable GCP Workload Observabiltiy</a></li>
<li class="toctree-l2"><a class="reference internal" href="monitor_goodput.html">ML Goodput Measurement</a></li>
<li class="toctree-l2"><a class="reference internal" href="use_vertex_ai_tensorboard.html">Use Vertex AI Tensorboard</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Features and Diagnostics</a></li>
<li class="toctree-l2"><a class="reference internal" href="pallas_kernels_performance.html">Performance Optimizations with Pallas Kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_metrics.html">Performance Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="understand_logs_and_metrics.html">Understand Logs and Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="checkpointing_solutions/gcs_checkpointing.html">GCS bucket-based checkpointing</a></li>
<li class="toctree-l2"><a class="reference internal" href="checkpointing_solutions/emergency_checkpointing.html">Emergency Checkpointing</a></li>
<li class="toctree-l2"><a class="reference internal" href="checkpointing_solutions/multi_tier_checkpointing.html">Multi-Tier Checkpointing</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax_ai_libraries_chosen.html">The JAX Ecosystem in MaxText: An Opinionated Guide</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../explanations.html">Explanations</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../explanations/steps_model.html">Steps to build a Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../explanations/quantization.html">Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../explanations/sharding.html">Sharding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../explanations/data_pipeline_perf.html">Data input pipeline performance</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../reference.html">Reference documentation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../reference/terminology.html">Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/supported_models_and_architectures.html">Supported Models &amp; Architectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/alternatives.html">Comparison to Alternatives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/benchmark_and_performance.html">Benchmark and Performance Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference/architecture_overview.html">MaxText architecture overview</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../development.html">How to Contribute</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/AI-Hypercomputer/maxtext" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/guides/features_and_diagnostics.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Features and Diagnostics</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#collect-stack-traces">Collect Stack Traces</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ahead-of-time-compilation-aot">Ahead of Time Compilation (AOT)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tpu-support">TPU Support</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-aot-1-compile-ahead-of-time-basics">Example AOT 1: Compile ahead of time basics</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-aot-2-save-compiled-function-then-load-and-run-it">Example AOT 2: Save compiled function, then load and run it</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpu-support">GPU Support</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatically-upload-logs-to-vertex-tensorboard">Automatically Upload Logs to Vertex Tensorboard</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <!--
 Copyright 2024 Google LLC

 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at

      https://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
 -->
<section class="tex2jax_ignore mathjax_ignore" id="features-and-diagnostics">
<h1>Features and Diagnostics<a class="headerlink" href="#features-and-diagnostics" title="Link to this heading">#</a></h1>
<section id="collect-stack-traces">
<h2>Collect Stack Traces<a class="headerlink" href="#collect-stack-traces" title="Link to this heading">#</a></h2>
<p>When running a Single Program, Multiple Data (SPMD) job on accelerators, the overall process can hang if there is any error or any VM hangs/crashes for some reason. In this scenario, capturing stack traces will help to identify and troubleshoot the issues for the jobs running on TPU VMs.</p>
<p>The following configurations will help to debug a fault or when a program is stuck or hung somewhere by collecting stack traces. Change the parameter values accordingly in <code class="docutils literal notranslate"><span class="pre">src/MaxText/configs/base.yml</span></code>:</p>
<ol class="arabic simple">
<li><p>Set <code class="docutils literal notranslate"><span class="pre">collect_stack_trace:</span> <span class="pre">True</span></code> to enable collection of stack traces on faults or when the program is hung. This setting will periodically dump the traces for the program to help in debugging. To disable this, set <code class="docutils literal notranslate"><span class="pre">collect_stack_trace:</span> <span class="pre">False</span></code>.</p></li>
<li><p>Set <code class="docutils literal notranslate"><span class="pre">stack_trace_to_cloud:</span> <span class="pre">False</span></code> to display stack traces on console. <code class="docutils literal notranslate"><span class="pre">stack_trace_to_cloud:</span> <span class="pre">True</span></code> will create a temporary file in <code class="docutils literal notranslate"><span class="pre">/tmp/debugging</span></code> in the TPUs to store the stack traces. There is an agent running on TPU VMs that will periodically upload the traces from the temporary directory to cloud logging in the gcp project. You can view the traces in Logs Explorer on Cloud Logging using the following query:</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">logName</span><span class="o">=</span><span class="s2">&quot;projects/&lt;project_name&gt;/logs/tpu.googleapis.com</span><span class="si">%2F</span><span class="s2">runtime_monitor&quot;</span>
<span class="n">jsonPayload</span><span class="o">.</span><span class="n">verb</span><span class="o">=</span><span class="s2">&quot;stacktraceanalyzer&quot;</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p><code class="docutils literal notranslate"><span class="pre">stack_trace_interval_seconds</span></code> signifies the duration in seconds between each stack trace collection event. Setting <code class="docutils literal notranslate"><span class="pre">stack_trace_interval_seconds:</span> <span class="pre">600</span></code> will collect the stack traces every 600 seconds (10 minutes).</p></li>
</ol>
<p>Here is the related PyPI package: <a class="reference external" href="https://pypi.org/project/cloud-tpu-diagnostics">https://pypi.org/project/cloud-tpu-diagnostics</a>.</p>
</section>
<section id="ahead-of-time-compilation-aot">
<h2>Ahead of Time Compilation (AOT)<a class="headerlink" href="#ahead-of-time-compilation-aot" title="Link to this heading">#</a></h2>
<p>To compile your training run ahead of time, we provide a tool <code class="docutils literal notranslate"><span class="pre">train_compile.py</span></code>. This tool allows you to compile the main <code class="docutils literal notranslate"><span class="pre">train_step</span></code> in <code class="docutils literal notranslate"><span class="pre">train.py</span></code> for target hardware (e.g. a large number of v5e devices) without using the full cluster.</p>
<section id="tpu-support">
<h3>TPU Support<a class="headerlink" href="#tpu-support" title="Link to this heading">#</a></h3>
<p>You may use only a CPU or a single VM from a different family to pre-compile for a TPU cluster. This compilation helps with two main goals:</p>
<ul class="simple">
<li><p>It will flag any out of memory (OOM) information, such as when the <code class="docutils literal notranslate"><span class="pre">per_device_batch_size</span></code> is set too high, with an identical OOM stack trace as if it was compiled on the target hardware.</p></li>
<li><p>The ahead of time compilation can be saved and then loaded for fast startup and restart times on the target hardware.</p></li>
</ul>
<p>The tool <code class="docutils literal notranslate"><span class="pre">train_compile.py</span></code> is tightly linked to <code class="docutils literal notranslate"><span class="pre">train.py</span></code> and uses the same configuration file <code class="docutils literal notranslate"><span class="pre">src/MaxText/configs/base.yml</span></code>. Although you don’t need to run on a TPU, you do need to install <code class="docutils literal notranslate"><span class="pre">jax[tpu]</span></code> in addition to other dependencies, so we recommend running <code class="docutils literal notranslate"><span class="pre">setup.sh</span></code> to install these if you have not already done so.</p>
<section id="example-aot-1-compile-ahead-of-time-basics">
<h4>Example AOT 1: Compile ahead of time basics<a class="headerlink" href="#example-aot-1-compile-ahead-of-time-basics" title="Link to this heading">#</a></h4>
<p>After installing the dependencies listed above, you are ready to compile ahead of time:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run the below on a single machine, e.g. a CPU</span>
python3<span class="w"> </span>MaxText.train_compile<span class="w"> </span>src/MaxText/configs/base.yml<span class="w"> </span><span class="nv">compile_topology</span><span class="o">=</span>v5e-256<span class="w"> </span><span class="nv">compile_topology_num_slices</span><span class="o">=</span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">global_parameter_scale</span><span class="o">=</span><span class="m">16</span><span class="w"> </span><span class="nv">per_device_batch_size</span><span class="o">=</span><span class="m">4</span>
</pre></div>
</div>
<p>This will compile a 16B parameter MaxText model on 2 v5e pods.</p>
</section>
<section id="example-aot-2-save-compiled-function-then-load-and-run-it">
<h4>Example AOT 2: Save compiled function, then load and run it<a class="headerlink" href="#example-aot-2-save-compiled-function-then-load-and-run-it" title="Link to this heading">#</a></h4>
<p>Here is an example that saves then loads the compiled <code class="docutils literal notranslate"><span class="pre">train_step</span></code>, starting with the save:</p>
<p><strong>Step 1: Run AOT and save compiled function</strong></p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run the below on a single machine, e.g. a CPU</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">LIBTPU_INIT_ARGS</span><span class="o">=</span><span class="s2">&quot;--xla_enable_async_all_gather=true&quot;</span>
python3<span class="w"> </span>-m<span class="w"> </span>MaxText.train_compile<span class="w"> </span>src/MaxText/configs/base.yml<span class="w"> </span><span class="nv">compile_topology</span><span class="o">=</span>v5e-256<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">compile_topology_num_slices</span><span class="o">=</span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">compiled_trainstep_file</span><span class="o">=</span>my_compiled_train.pickle<span class="w"> </span><span class="nv">global_parameter_scale</span><span class="o">=</span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">per_device_batch_size</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="nv">steps</span><span class="o">=</span><span class="m">10000</span><span class="w"> </span><span class="nv">learning_rate</span><span class="o">=</span>1e-3
</pre></div>
</div>
<p><strong>Step 2: Run train.py and load the compiled function</strong></p>
<p>To load the compiled train_step, you just need to pass <code class="docutils literal notranslate"><span class="pre">compiled_trainstep_file=my_compiled_train.pickle</span></code> into <code class="docutils literal notranslate"><span class="pre">train.py</span></code>:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run the below on each host of the target hardware, e.g. each host on 2 slices of v5e-256</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">LIBTPU_INIT_ARGS</span><span class="o">=</span><span class="s2">&quot;--xla_enable_async_all_gather=true&quot;</span>
python3<span class="w"> </span>-m<span class="w"> </span>MaxText.train<span class="w"> </span>src/MaxText/configs/base.yml<span class="w"> </span><span class="nv">run_name</span><span class="o">=</span>example_load_compile<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">compiled_trainstep_file</span><span class="o">=</span>my_compiled_train.pickle<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">global_parameter_scale</span><span class="o">=</span><span class="m">16</span><span class="w">  </span><span class="nv">per_device_batch_size</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="nv">steps</span><span class="o">=</span><span class="m">10000</span><span class="w"> </span><span class="nv">learning_rate</span><span class="o">=</span>1e-3<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">base_output_directory</span><span class="o">=</span>gs://my-output-bucket<span class="w"> </span><span class="nv">dataset_path</span><span class="o">=</span>gs://my-dataset-bucket
</pre></div>
</div>
<p>In the save step of example 2 above we included exporting the compiler flag <code class="docutils literal notranslate"><span class="pre">LIBTPU_INIT_ARGS</span></code> and <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> because those affect the compiled object <code class="docutils literal notranslate"><span class="pre">my_compiled_train.pickle.</span></code> The sizes of the model (e.g. <code class="docutils literal notranslate"><span class="pre">global_parameter_scale</span></code>, <code class="docutils literal notranslate"><span class="pre">max_sequence_length</span></code> and <code class="docutils literal notranslate"><span class="pre">per_device_batch</span></code>) are fixed when you initially compile via <code class="docutils literal notranslate"><span class="pre">compile_train.py</span></code>, you will see a size error if you try to run the saved compiled object with different sizes than you compiled with. However a subtle note is that the <strong>learning rate schedule</strong> is also fixed when you run <code class="docutils literal notranslate"><span class="pre">compile_train</span></code> - which is determined by both <code class="docutils literal notranslate"><span class="pre">steps</span></code> and <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>. The optimizer parameters such as  <code class="docutils literal notranslate"><span class="pre">adam_b1</span></code> are passed only as shaped objects to the compiler - thus their real values are determined when you run <code class="docutils literal notranslate"><span class="pre">train.py</span></code>, not during the compilation. If you do pass in different shapes (e.g. <code class="docutils literal notranslate"><span class="pre">per_device_batch</span></code>), you will get a clear error message reporting that the compiled signature has different expected shapes than what was input. If you attempt to run on different hardware than the compilation targets requested via <code class="docutils literal notranslate"><span class="pre">compile_topology</span></code>, you will get an error saying there is a failure to map the devices from the compiled to your real devices. Using different XLA flags or a LIBTPU than what was compiled will probably run silently with the environment you compiled in without error. However there is no guaranteed behavior in this case; you should run in the same environment you compiled in.</p>
</section>
</section>
<section id="gpu-support">
<h3>GPU Support<a class="headerlink" href="#gpu-support" title="Link to this heading">#</a></h3>
<p>Ahead-of-time compilation is also supported for GPUs with some differences from TPUs:</p>
<ol class="arabic simple">
<li><p>GPU does not support compilation across hardware: A GPU host is still required to run AoT compilation, but a single GPU host can compile a program for a larger cluster of the same hardware.</p></li>
<li><p>For <a class="reference external" href="https://cloud.google.com/compute/docs/gpus#h100-gpus">A3 Cloud GPUs</a>, the maximum “slice” size is a single host, and the <code class="docutils literal notranslate"><span class="pre">compile_topology_num_slices</span></code> parameter represents the number of A3 machines to precompile for.</p></li>
</ol>
<section id="example">
<h4>Example<a class="headerlink" href="#example" title="Link to this heading">#</a></h4>
<p>This example illustrates the flags to use for a multihost GPU compilation targeting a cluster of 4 A3 hosts:</p>
<p><strong>Step 1: Run AOT and save compiled function</strong></p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run the below on a single A3 machine</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">XLA_FLAGS</span><span class="o">=</span><span class="s2">&quot;--xla_gpu_enable_async_collectives=true&quot;</span>
python3<span class="w"> </span>-m<span class="w"> </span>MaxText.train_compile<span class="w"> </span>src/MaxText/configs/base.yml<span class="w"> </span><span class="nv">compile_topology</span><span class="o">=</span>a3<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">compile_topology_num_slices</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">compiled_trainstep_file</span><span class="o">=</span>my_compiled_train.pickle<span class="w"> </span><span class="nv">global_parameter_scale</span><span class="o">=</span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">attention</span><span class="o">=</span>dot_product<span class="w"> </span><span class="nv">per_device_batch_size</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="nv">steps</span><span class="o">=</span><span class="m">10000</span><span class="w"> </span><span class="nv">learning_rate</span><span class="o">=</span>1e-3
</pre></div>
</div>
<p><strong>Step 2: Run <code class="docutils literal notranslate"><span class="pre">train.py</span></code> and load the compiled function</strong></p>
<p>To load the compiled train_step, you just need to pass <code class="docutils literal notranslate"><span class="pre">compiled_trainstep_file=my_compiled_train.pickle</span></code> into <code class="docutils literal notranslate"><span class="pre">train.py</span></code>:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run the below on each of the 4 target A3 hosts.</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">XLA_FLAGS</span><span class="o">=</span><span class="s2">&quot;--xla_gpu_enable_async_collectives=true&quot;</span>
python3<span class="w"> </span>-m<span class="w"> </span>MaxText.train<span class="w"> </span>src/MaxText/configs/base.yml<span class="w"> </span><span class="nv">run_name</span><span class="o">=</span>example_load_compile<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">compiled_trainstep_file</span><span class="o">=</span>my_compiled_train.pickle<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">attention</span><span class="o">=</span>dot_product<span class="w"> </span><span class="nv">global_parameter_scale</span><span class="o">=</span><span class="m">16</span><span class="w">  </span><span class="nv">per_device_batch_size</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="nv">steps</span><span class="o">=</span><span class="m">10000</span><span class="w"> </span><span class="nv">learning_rate</span><span class="o">=</span>1e-3<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nv">base_output_directory</span><span class="o">=</span>gs://my-output-bucket<span class="w"> </span><span class="nv">dataset_path</span><span class="o">=</span>gs://my-dataset-bucket
</pre></div>
</div>
<p>As in the TPU case, note that the compilation environment must match the execution environment, in this case by setting the same <code class="docutils literal notranslate"><span class="pre">XLA_FLAGS</span></code>.</p>
</section>
</section>
</section>
<section id="automatically-upload-logs-to-vertex-tensorboard">
<h2>Automatically Upload Logs to Vertex Tensorboard<a class="headerlink" href="#automatically-upload-logs-to-vertex-tensorboard" title="Link to this heading">#</a></h2>
<p>MaxText supports automatic upload of logs collected in a directory to a Tensorboard instance in Vertex AI. Follow <a class="reference internal" href="use_vertex_ai_tensorboard.html"><span class="std std-doc">Use Vertex AI Tensorboard</span></a> to know more.</p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="use_vertex_ai_tensorboard.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Use Vertex AI Tensorboard</p>
      </div>
    </a>
    <a class="right-next"
       href="pallas_kernels_performance.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Performance Optimizations with Pallas Kernels</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#collect-stack-traces">Collect Stack Traces</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ahead-of-time-compilation-aot">Ahead of Time Compilation (AOT)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tpu-support">TPU Support</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-aot-1-compile-ahead-of-time-basics">Example AOT 1: Compile ahead of time basics</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-aot-2-save-compiled-function-then-load-and-run-it">Example AOT 2: Save compiled function, then load and run it</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpu-support">GPU Support</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatically-upload-logs-to-vertex-tensorboard">Automatically Upload Logs to Vertex Tensorboard</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By MaxText developers
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025, MaxText developers.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>